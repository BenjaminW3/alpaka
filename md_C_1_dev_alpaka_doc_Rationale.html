<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9"/>
<title>alpaka: Rationale</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">alpaka
   </div>
   <div id="projectbrief">Abstraction Library for Parallel Kernel Acceleration</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('md_C_1_dev_alpaka_doc_Rationale.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Rationale </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Kernels </h2>
<h3>Requirements</h3>
<ul>
<li>User kernels should be implemented independent of the accelerator.</li>
<li>A user kernel has to have access to accelerator methods like synchronization within blocks, index retrieval and many more.</li>
<li>For usage with CUDA the kernel methods have to be attributed with __device__ __host__.</li>
<li>The user kernel has to fulfill std::is_trivially_copyable because only such objects can be copied into CUDA device memory. A trivially copyable class is a class that<ol type="1">
<li>Has no non-trivial copy constructors(this also requires no virtual functions or virtual bases)</li>
<li>Has no non-trivial move constructors</li>
<li>Has no non-trivial copy assignment operators</li>
<li>Has no non-trivial move assignment operators</li>
<li>Has a trivial destructor</li>
</ol>
</li>
</ul>
<h3>Implementation Variants</h3>
<p>There are two possible ways to tell the kernel about the accelerator type:</p><ol type="1">
<li>The kernel is templated on the accelerator type<ul>
<li>+ This allows users to specialize them for different accelerators. (Is this is really necessary or desired?)</li>
<li>- The kernel has to be a class template. This does not allow C++ lambdas to be used as kernels because they are no templates themselves (but only their <code>operator()</code> can be templated in C++14).</li>
<li>- This prevents the user from instantiating an accelerator independent kernel before executing it and then adapting it to the given accelerator on execution. Because the memory layout in inheritance hierarchies is undefined a simple copy of the user kernel or its members to its specialized type is not possible platform independently. This would require a copy from UserKernel&lt;TDummyAcc&gt; to UserKernel&lt;TAcc&gt; to be possible. The only way to allow this would be to require the user to implement a templated copy constructor for every kernel. This is not allowed for kernels that should be copyable to a CUDA device because std::is_trivially_copyable requires the kernel to have no non-trivial copy constructors.</li>
<li>a) and inherits from the accelerator.<ul>
<li>+/- To give a device function called from the kernel functor access to the accelerator methods, these methods have to be templated on the accelerated kernel and get a reference to the accelerator. This allows to give them access not only to the accelerator methods but also to the other kernel methods. This is inconsistent because the kernel uses inheritance and subsequent function calls get a parameter.</li>
<li>- The kernel itself has to inherit at least protected from the accelerator to allow the KernelExecutor to access the Accelerator.</li>
<li>- How do accelerator functions called from the kernel (and not within the kernel class itself) access the accelerator methods? Casting this to the accelerator type and giving it as parameter is too much to require from the user.</li>
</ul>
</li>
<li>b) and has a reference to the accelerator as parameter.<ul>
<li>+ This allows to use the accelerator in accelerator functions called from the kernel (and not within the kernel class itself) to access the accelerator methods in the same way the kernel entry point function can.</li>
<li>- This would require an additional object (the accelerator) in device memory taking up valuable CUDA registers (opposed to the inheritance solution). At least on CUDA all the accelerator functions could be inlined nevertheless.</li>
</ul>
</li>
</ul>
</li>
<li>The <code>operator()</code> is templated on the accelerator type and has a reference to the accelerator as parameter.<ul>
<li>+ The kernel can be an arbitrary function object with ALPAKA_FCT_HOST_ACC attributes.</li>
<li>+ This would allow to instantiate the accelerator independent kernel and set its members before execution.</li>
<li>+/- C++14 provides polymorphic lambdas. All compilers (even MSVC) support this. Inheriting from a non capturing lambda for the KernelExecutor is allowed. (TODO: How to check for a non capturing lambda?)</li>
<li>- The <code>operator()</code> could be overloaded on the accelerator type but not the kernel itself, so it always has the same members.</li>
<li>- This would require an additional object (the accelerator) in device memory taking up valuable CUDA registers (opposed to the inheritance solution). At least on CUDA all the accelerator functions could be inlined nevertheless.</li>
</ul>
</li>
</ol>
<h3>Implementation Notes</h3>
<p>Currently we implement version 1b).</p>
<p>Kernels bound to an accelerator can be built with the <code>createKernelExecutor</code> template function. This function returns an object that stores the given kernel type and the constructor argumnts.. To separate the kernel execution attributes (grid/block-extents, stream) from the invocation arguments, the first call to <code>operator()</code> returns a kernel executor with stored execution attributes. The returned executor can then be executed with the <code>operator()</code> leading to <code>createKernelExecutor&lt;TAcc, TKernel&gt;(TKernelConstrArgs ... args)(&lt;grid/block&gt;-extents, stream = 0)(invocation-args ...)</code> for a complete kernel invocation.</p>
<p>TODO: Why do we require the user to have a default template argument <code>template&lt;typename TAcc = <a class="el" href="classalpaka_1_1IAcc.html" title="The accelerator interface. ">alpaka::IAcc</a>&lt;&gt;&gt;</code> for the kernel?</p><ul>
<li>Because we can not create a kernel before binding it to an accelerator we could just make it a simple template <code>template&lt;typename TAcc&gt;</code> and make IAcc an implementation detail.</li>
<li>If it is because the possible use of boost::mpl::_1, would it be better to not require the usage of IAcc and make it an implementation detail requiring the user to use <code>template&lt;typename TAcc = boost::mpl::_1&gt;</code> directly?</li>
<li>Why is boost::mpl::_1 even required in this case?</li>
</ul>
<h3>External Block Shared Memory</h3>
<p>The size of the external block shared memory has to be available at compile time.</p>
<p>TODO: Why?</p>
<p>TODO: Explain trait.</p>
<h2>Accelerators </h2>
<p>All the accelerators are restricted by the possibilities of CUDA.</p>
<p>The library does not use a common accelerator base class with virtual functions from which all accelerator implementations inherit (run-time polymorphism). This is required because in the case of CUDA copying objects (kernels inheriting from the accelerator) with virtual functions into device memory is not viable because of possibly incompatible object layout (std::is_trivially_copyable). To deliver a common accelerator interface static polymorphism is used instead.</p>
<p>The accelerator interface IAcc hides all implementation details of the underlying accelerator base class by protected inheritance. Private inheritance is not possible, because the <code>KernelExecutor</code> implementation for a special accelerator sometimes needs access to the accelerator itself in <code>KernelExecutor&lt;IAcc&lt;Acc&gt;&gt;</code>.</p>
<p>TODO: Add note about ALPAKA_FCT_HOST_ACC!</p>
<h2>Accelerator Implementation Notes </h2>
<h3>Serial</h3>
<p>The serial accelerator is only for debugging purposes because it only allows blocks with exactly one kernel. Therefore it does not implement real synchronization or atomic primitives.</p>
<h3>Threads</h3>
<h4>Execution</h4>
<p>To prevent recreation of the threads between execution of different blocks in the grid, the threads are stored inside a thread pool. This thread pool is local to the invocation because making it local to the KernelExecutor could mean a heavy memory usage and lots of idling threads when there are multiple KernelExecutors around. Because the default policy of the threads in the pool is to yield instead of waiting, this would also slow down the system immensely.</p>
<h3>Fibers</h3>
<h4>Execution</h4>
<p>To prevent recreation of the fibers between execution of different blocks in the grid, the fibers are stored inside a fibers pool. This fibers pool is local to the invocation because making it local to the KernelExecutor could mean a heavy memory usage when there are multiple KernelExecutors around.</p>
<h3>OpenMP</h3>
<h4>Execution</h4>
<p>Parallel execution of the kernels in a block is required because when syncBlockThreads is called all of them have to be done with their work up to this line. So we have to spawn one real thread per kernel in a block. <code>omp for</code> is not useful because it is meant for cases where multiple iterations are executed by one thread but in our case a 1:1 mapping is required. Therefore we use <code>omp parallel</code> with the specified number of threads in a block. Another reason for not using <code>omp for</code> like <code>#pragma omp parallel for collapse(3) num_threads(blockDim.x*blockDim.y*blockDim.z)</code> is that <code>#pragma omp barrier</code> used for intra block synchronization is not allowed inside <code>omp for</code> blocks.</p>
<p>Because OpenMP is designed for a 1:1 abstraction of hardware to software threads, the block size is restricted by the number of OpenMP threads allowed by the runtime. This could be as little as 2 or 4 kernels but on a system with 4 cores with hyperthreading OpenMP can for example also allow a maximum of 64 threads.</p>
<h4>Index</h4>
<p>OpenMP only provides a linear thread index. This index is converted to a 3 dimensional index at runtime.</p>
<h4>Atomic</h4>
<p>We can not use '#pragma omp atomic' because braces or calling other functions directly after <code>#pragma omp atomic</code> are not allowed! Because we are implementing the CUDA atomic operations which return the old value, this requires <code>#pragma omp critical</code> to be used. <code>omp_set_lock</code> is an alternative but is usually slower.</p>
<h3>CUDA</h3>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Mar 6 2015 23:52:34 for alpaka by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.9 </li>
  </ul>
</div>
</body>
</html>
